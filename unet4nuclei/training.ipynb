{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend\n",
    "import keras.callbacks\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.optimizers\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('SVG')\n",
    "\n",
    "import helper.callbacks\n",
    "import helper.model_builder\n",
    "import helper.visualize\n",
    "import helper.data_provider\n",
    "import helper.metrics\n",
    "\n",
    "import skimage.io\n",
    "import sklearn.metrics\n",
    "\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "const_lr = 1e-4\n",
    "\n",
    "tag = '01'\n",
    "\n",
    "# Output dirs\n",
    "out_dir = '/data1/image-segmentation/BBBC022/unet/experiments/' + tag + '/out'\n",
    "tb_log_dir = \"/data1/image-segmentation/BBBC022/unet/tensorboard/\" + tag + \"/\"\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "os.makedirs(tb_log_dir, exist_ok=True)\n",
    "\n",
    "# Files\n",
    "chkpt_file = \"/data1/image-segmentation/BBBC022/unet/experiments/\" + tag + \"/checkpoints/{epoch:04d}.hdf5\"\n",
    "csv_log_file = \"/data1/image-segmentation/BBBC022/unet/experiments/\" + tag + \"/log.csv\"\n",
    "\n",
    "# Input dirs\n",
    "train_dir_x = '/data1/image-segmentation/BBBC022/unet/split/training/x/'\n",
    "train_dir_y = '/data1/image-segmentation/BBBC022/unet/split/training/y/'\n",
    "val_dir = \"/data1/image-segmentation/BBBC022/unet/split/validation/\"\n",
    "\n",
    "# Learning Settings\n",
    "rescale_labels = False\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "batch_size = 4\n",
    "steps_per_epoch = 2 * 4 / batch_size\n",
    "\n",
    "# make sure these number for to the validation set\n",
    "val_batch_size = 10\n",
    "val_steps = int(50 * 4 / val_batch_size)\n",
    "\n",
    "# generator only params\n",
    "dim1 = 256\n",
    "dim2 = 256\n",
    "\n",
    "bit_depth = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build session running on GPU 1\n",
    "configuration = tf.ConfigProto()\n",
    "#configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"\"\n",
    "session = tf.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)\n",
    "\n",
    "train_gen = helper.data_provider.random_sample_generator(\n",
    "    train_dir_x,\n",
    "    train_dir_y,\n",
    "    batch_size,\n",
    "    bit_depth,\n",
    "    dim1,\n",
    "    dim2,\n",
    "    rescale_labels\n",
    ")\n",
    "\n",
    "val_gen = helper.data_provider.single_data_from_images(\n",
    "    val_dir + 'x/',\n",
    "     val_dir + 'y/',\n",
    "     val_batch_size,\n",
    "     bit_depth,\n",
    "     dim1,\n",
    "     dim2,\n",
    "     rescale_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = helper.model_builder.get_model_3_class(dim1, dim2)\n",
    "model.summary()\n",
    "\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [keras.metrics.categorical_accuracy, helper.metrics.recall, helper.metrics.precision]\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr = const_lr)\n",
    "\n",
    "model.compile(loss=loss, metrics=metrics, optimizer=optimizer)\n",
    "\n",
    "# CALLBACKS\n",
    "# save model after each epoch\n",
    "callback_model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=chkpt_file,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=False\n",
    ")\n",
    "callback_csv = keras.callbacks.CSVLogger(filename=csv_log_file)\n",
    "# callback_splits_and_merges = helper.callbacks.SplitsAndMergesLoggerBoundary(\n",
    "#     'images',\n",
    "#     val_gen,\n",
    "#     gen_calls = val_steps,\n",
    "#     log_dir=tb_log_dir\n",
    "# )\n",
    "\n",
    "callbacks=[callback_model_checkpoint, callback_csv] #, callback_splits_and_merges]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "statistics = model.fit_generator(\n",
    "    generator=train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# visualize learning stats\n",
    "#helper.visualize.visualize_learning_stats_boundary_hard(statistics, out_dir, metrics)\n",
    "\n",
    "print('Done! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
