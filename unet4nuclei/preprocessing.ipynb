{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing input images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib \n",
    "import random\n",
    "import scipy.stats\n",
    "import shutil\n",
    "\n",
    "import skimage.filters\n",
    "import skimage.io\n",
    "import skimage.segmentation\n",
    "\n",
    "import utils.data_augmentation\n",
    "import utils.data_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume a nucleus is at least 10 by 10 pixels big\n",
    "min_nucleus_size = 3\n",
    "\n",
    "# Transform gray scale TIF images to PNG\n",
    "transform_images_to_PNG = False\n",
    "\n",
    "# Pixels of the boundary (min 2 pixels)\n",
    "boundary_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "dir_root = '/home/cells2numbers/2017_08_unet/data/'\n",
    "\n",
    "# raw data\n",
    "dir_raw_images = dir_root + 'raw_images/'\n",
    "dir_raw_annotations = dir_root + 'raw_annotations/'\n",
    "\n",
    "# Split files\n",
    "create_split_files = True\n",
    "\n",
    "path_files_training = dir_root + 'training.txt'\n",
    "path_files_validation = dir_root + 'validation.txt'\n",
    "path_files_test = dir_root + 'test.txt'\n",
    "\n",
    "if create_split_files:\n",
    "    file_list = os.listdir(dir_raw_images)\n",
    "\n",
    "    [list_training, list_test, list_validation] = utils.data_split.create_image_lists(dir_raw_images,.5,.25)\n",
    "\n",
    "    utils.data_split.write_path_files(path_files_training, list_training)\n",
    "    utils.data_split.write_path_files(path_files_test, list_test)\n",
    "    utils.data_split.write_path_files(path_files_validation, list_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directories\n",
    "\n",
    "## split folders\n",
    "dir_training = dir_root + 'unet/split/training/'\n",
    "dir_validation = dir_root + 'unet/split/validation/'\n",
    "dir_test = dir_root + 'unet/split/test/'\n",
    "\n",
    "## boundary experiment\n",
    "dir_boundary_labels = dir_root + 'unet/y/'\n",
    "\n",
    "## input data, normalized and 8 bit\n",
    "dir_images_normalized_8bit = dir_root + 'unet/x/'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(dir_training, exist_ok=True)\n",
    "os.makedirs(dir_validation, exist_ok=True)\n",
    "os.makedirs(dir_test, exist_ok=True)\n",
    "os.makedirs(dir_boundary_labels, exist_ok=True)\n",
    "os.makedirs(dir_images_normalized_8bit, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Output Targets: Three Class Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filelist = sorted(os.listdir(dir_raw_annotations))\n",
    "\n",
    "# run over all raw images\n",
    "for filename in filelist:\n",
    "    \n",
    "    # GET ANNOTATION\n",
    "    annot = skimage.io.imread(dir_raw_annotations + filename)\n",
    "    \n",
    "    # strip the first channel\n",
    "    if len(annot.shape) == 3:\n",
    "        annot = annot[:,:,0]\n",
    "    \n",
    "    \n",
    "    # label the annotations nicely to prepare for future filtering operation\n",
    "    annot = skimage.morphology.label(annot)\n",
    "    \n",
    "    # filter small objects, e.g. micronulcei\n",
    "    annot = skimage.morphology.remove_small_objects(annot, min_size=min_nucleus_size)\n",
    "    \n",
    "    # find boundaries\n",
    "    boundaries = skimage.segmentation.find_boundaries(annot)\n",
    "\n",
    "    for k in range(2, boundary_size, 2):\n",
    "        boundaries = skimage.morphology.binary_dilation(boundaries)\n",
    "        \n",
    "    # BINARY LABEL\n",
    "    \n",
    "    # prepare buffer for binary label\n",
    "    label_binary = np.zeros((annot.shape + (3,)))\n",
    "    \n",
    "    # write binary label\n",
    "    label_binary[(annot == 0) & (boundaries == 0), 0] = 1\n",
    "    label_binary[(annot != 0) & (boundaries == 0), 1] = 1\n",
    "    label_binary[boundaries == 1, 2] = 1\n",
    "    \n",
    "    # save it - converts image to range from 0 to 255\n",
    "    skimage.io.imsave(dir_boundary_labels + filename, label_binary)\n",
    "    \n",
    "    if(debug):\n",
    "        print(annot.dtype, annot.shape)\n",
    "        \n",
    "        # plot original annotation\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(annot)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "        # plot boundary labels\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(label_binary)\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if transform_images_to_PNG:\n",
    "\n",
    "    filelist = sorted(os.listdir(dir_raw_images))\n",
    "\n",
    "    # run over all raw images\n",
    "    for filename in filelist:\n",
    "\n",
    "        # load image and its annotation\n",
    "        img = skimage.io.imread(dir_raw_images + filename)\n",
    "\n",
    "        if(debug):\n",
    "            print(\"BEFORE\")\n",
    "            print(img.dtype, img.shape)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            plt.hist(img.flatten())\n",
    "            plt.show()        \n",
    "\n",
    "        # IMAGE\n",
    "\n",
    "        # normalize to [0,1]\n",
    "        percentile = 99.9\n",
    "        high = np.percentile(img, percentile)\n",
    "        low = np.percentile(img, 100-percentile)\n",
    "\n",
    "        img = np.minimum(high, img)\n",
    "        img = np.maximum(low, img)\n",
    "\n",
    "        img = (img - low) / (high - low) # gives float64, thus cast to 8 bit later\n",
    "        img = skimage.img_as_ubyte(img) \n",
    "\n",
    "        skimage.io.imsave(dir_images_normalized_8bit + filename[:-3] + 'png', img)\n",
    "\n",
    "        if(debug):\n",
    "            print(\"AFTER\")\n",
    "            print(img.dtype, img.shape)\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "            plt.hist(img.flatten())\n",
    "            plt.show()\n",
    "else:\n",
    "    dir_images_normalized_8bit = dir_raw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment images (optional) \n",
    "* data augmentation using affine transformations \n",
    "* n_points x n_points data points are equally distributed in the image \n",
    "* distort \n",
    "* n_augmentations images are calculated for each image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation taks lots of times but only has to be computed once \n",
    "augment_images =  0\n",
    "\n",
    "# augmentation parameters \n",
    "n_points = 10\n",
    "distort = 5\n",
    "\n",
    "# number of augmented images\n",
    "n_augmentations = 10\n",
    "\n",
    "if augment_images: \n",
    "\n",
    "    filelist = sorted(os.listdir(dir_images_normalized_8bit))\n",
    "    \n",
    "    # run over all raw images\n",
    "    for filename in filelist:\n",
    "            \n",
    "        # check if boundary labels were calculated \n",
    "        my_file = pathlib.Path(dir_boundary_labels + filename)\n",
    "        \n",
    "        if my_file.is_file():\n",
    "            \n",
    "            # load image \n",
    "            x = skimage.io.imread(dir_images_normalized_8bit + filename)\n",
    "            # load annotation \n",
    "            y = skimage.io.imread(dir_boundary_labels + filename)\n",
    "            \n",
    "            for n in range(1,n_augmentations):\n",
    "                # augment image and annotation \n",
    "                x_augmented, y_augmented = utils.data_augmentation.deform(x, y, points = n_points, distort = distort)\n",
    "                # filename for augmented images\n",
    "                filename_augmented = os.path.splitext(filename)[0] + '_aug_{:03d}'.format(n) + os.path.splitext(filename)[1]\n",
    "                skimage.io.imsave(dir_images_normalized_8bit + filename_augmented, x)\n",
    "                skimage.io.imsave(dir_boundary_labels + filename_augmented, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Up\n",
    "- Split up in training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_files_training) as f:\n",
    "    training_files = f.read().splitlines()\n",
    "with open(path_files_validation) as f:\n",
    "    validation_files = f.read().splitlines()\n",
    "with open(path_files_test) as f:\n",
    "    test_files = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 0 suffix because Keras thinks everything is a classification task organized in directories.\n",
    "\n",
    "os.makedirs(dir_training + 'x/', exist_ok=True)\n",
    "os.makedirs(dir_validation + 'x/0/', exist_ok=True)\n",
    "os.makedirs(dir_test + 'x/0/', exist_ok=True)\n",
    "\n",
    "os.makedirs(dir_training + 'y/', exist_ok=True)\n",
    "os.makedirs(dir_validation + 'y/0/', exist_ok=True)\n",
    "os.makedirs(dir_test + 'y/0/', exist_ok=True)\n",
    "\n",
    "for filename in training_files:\n",
    "    shutil.copyfile(dir_images_normalized_8bit + filename, dir_training + 'x/' + filename)\n",
    "    shutil.copyfile(dir_boundary_labels + filename, dir_training + 'y/' + filename)\n",
    "    \n",
    "for filename in validation_files:\n",
    "    shutil.copyfile(dir_images_normalized_8bit + filename, dir_validation + 'x/0/' + filename)\n",
    "    shutil.copyfile(dir_boundary_labels + filename, dir_validation + 'y/0/' + filename)\n",
    "    \n",
    "for filename in test_files:\n",
    "    shutil.copyfile(dir_images_normalized_8bit + filename, dir_test + 'x/0/' + filename)\n",
    "    shutil.copyfile(dir_boundary_labels + filename, dir_test + 'y/0/' + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
